{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f840735",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990e1ef",
   "metadata": {},
   "source": [
    "## Loading e Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a9aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vasco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vasco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vasco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from collections import Counter\n",
    "import itertools \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e39dd",
   "metadata": {},
   "source": [
    "Loading dos datasets como dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ddc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0  This is your typical cheerful and colorful MGM...   pos\n",
      "1  As a another reviewer states Hanna's War is an...   pos\n",
      "2  One of the best \"Amitabh comeback\" movies I li...   pos\n",
      "3  Peter Sollett has created an endearing portrai...   pos\n",
      "4  The film is not visually stunning in the conve...   pos\n",
      "5  This is not Bela Lagosi's best movie, but it's...   pos\n",
      "6  I happened to watch this movie by chance some ...   pos\n",
      "7  So many consider The Black Cat as the best Kar...   pos\n",
      "8  I saw this at a screening last night too. I wa...   pos\n",
      "9  One of the best true crime movies ever made an...   pos\n",
      "                                                text label\n",
      "0  Logan Lerman & Dean Collins III of Jack & Bobb...   pos\n",
      "1  I have seen this film on a Sunday evening and ...   pos\n",
      "2  Two great stars and a legendary Director creat...   pos\n",
      "3  I'm originally from Brazil... the sad thing ab...   pos\n",
      "4  \"Witchery\" is a decent little Euro Trash horro...   pos\n",
      "5  The best so bad it's good movie ever made. Rud...   pos\n",
      "6  Okay, I'll say it. This movie made me laugh so...   pos\n",
      "7  This movie almost has everything. The action i...   pos\n",
      "8  This movie is ageless and would probably appea...   pos\n",
      "9  Great book, great movie, great soundtrack. Fra...   pos\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"imdb_reviews_train.csv\", encoding=\"utf-8\")\n",
    "test_df = pd.read_csv(\"imdb_reviews_test.csv\", encoding=\"utf-8\")\n",
    "print(train_df.head(10))\n",
    "print(test_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e35d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN df => 21754 reviews\n",
      "TEST df =>  21996 reviews\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN df => {len(train_df)} reviews\")\n",
    "print(f\"TEST df =>  {len(test_df)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142a118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(train_df['label']==\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TRAIN set tem 10776 reviews positivas\n",
      " TRAIN set tem 10978 reviews negativas\n",
      " TEST set tem 10946 reviews positivas\n",
      " TEST set tem 11050 reviews negativas\n"
     ]
    }
   ],
   "source": [
    "print(f\" TRAIN set tem {sum(train_df['label']==\"pos\")} reviews positivas\")\n",
    "print(f\" TRAIN set tem {sum(train_df['label']==\"neg\")} reviews negativas\")\n",
    "\n",
    "print(f\" TEST set tem {sum(test_df['label']==\"pos\")} reviews positivas\")\n",
    "print(f\" TEST set tem {sum(test_df['label']==\"neg\")} reviews negativas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb1c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is your typical cheerful and colorful MGM musical from the early \\'50\\'s and it\\'s definitely on of the better ones to watch out there. The movie got directed by the genre expert Vincente Minnelli and stars Gene Kelly in the main lead. Both did quite a few movies together back in those days, of which this one is probably their best known one.  The movie itself actually managed to win the best picture Oscar over the year, which meant it beat out movies such as \"A Place in the Sun\", \"A Streetcar Named Desire\", \"The African Queen\", \"Quo Vadis\", \"The Blue Veil\", \"Death of a Salesman\" that year. A real accomplishment of course but at the same time also a bit too much credit for this delightful, bright and entertaining movie. When you watch this movie you surely will be entertained by it all, which is also thanks to the movie its beautiful color look and the many nice characters within this movie. The musical numbers are also all nicely done, which is no big surprise when you have people such as Vincente Minnelli and Gene Kelly at work.  But really, couldn\\'t had everything that got told in this movie been done in halve an hour less or so? I mean, we already know where the movie is heading to but yet it manages to stretch it out all for as long as possible. Not that it makes the movie drag in any parts, it just makes it a bit overlong. The movie could had also definitely been done with a few less musical numbers in it. One of the better MGM musicals, that is not without its flaws though. 8 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exemplo de review (neste caso, positiva)\n",
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285fa07",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e5a16",
   "metadata": {},
   "source": [
    "Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c356b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        this is your typical cheerful and colorful mgm...\n",
       "1        as a another reviewer states hanna's war is an...\n",
       "2        one of the best \"amitabh comeback\" movies i li...\n",
       "3        peter sollett has created an endearing portrai...\n",
       "4        the film is not visually stunning in the conve...\n",
       "                               ...                        \n",
       "21749    in the third entry of the phantasm series, mik...\n",
       "21750    this movie still chills me to the bone thinkin...\n",
       "21751    is this film a joke? is it a comedy? surely it...\n",
       "21752    all of david prior's movies are terrible on al...\n",
       "21753    this should have been a movie about sam and hi...\n",
       "Name: text, Length: 21754, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converte todas as letras para minúsculas\n",
    "train_lower = train_df['text'].apply(lambda x: x.lower())\n",
    "# mesmo para o conjunto de teste\n",
    "test_lower = test_df['text'].apply(lambda x: x.lower())\n",
    "train_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3831e3d",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c5f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [this, is, your, typical, cheerful, and, color...\n",
       "1        [as, a, another, reviewer, states, hanna, 's, ...\n",
       "2        [one, of, the, best, ``, amitabh, comeback, ''...\n",
       "3        [peter, sollett, has, created, an, endearing, ...\n",
       "4        [the, film, is, not, visually, stunning, in, t...\n",
       "                               ...                        \n",
       "21749    [in, the, third, entry, of, the, phantasm, ser...\n",
       "21750    [this, movie, still, chills, me, to, the, bone...\n",
       "21751    [is, this, film, a, joke, ?, is, it, a, comedy...\n",
       "21752    [all, of, david, prior, 's, movies, are, terri...\n",
       "21753    [this, should, have, been, a, movie, about, sa...\n",
       "Name: text, Length: 21754, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokeniza com word_tokenize\n",
    "train_tokens = train_lower.apply(nltk.word_tokenize)\n",
    "# mesmo para o conjunto de teste\n",
    "test_tokens = test_lower.apply(nltk.word_tokenize)\n",
    "train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a frequência de tokens\n",
    "def freq(token_lists):\n",
    "    all_tokens = list(itertools.chain(*token_lists))  # Unifica todas as listas em uma só (frases em uma lista)\n",
    "    freq = Counter(all_tokens)  # Conta a frequência de cada token\n",
    "    freq_df = pd.DataFrame(freq.items(), columns=['Token', 'Frequência']).sort_values(by=\"Frequência\", ascending=False)\n",
    "    return freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed3732",
   "metadata": {},
   "source": [
    "Tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020df921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequência</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>221278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>188548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>,</td>\n",
       "      <td>176455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>109996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>a</td>\n",
       "      <td>109552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>of</td>\n",
       "      <td>95082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>to</td>\n",
       "      <td>88314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>75184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it</td>\n",
       "      <td>69164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>i</td>\n",
       "      <td>67269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>in</td>\n",
       "      <td>60621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this</td>\n",
       "      <td>57822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>that</td>\n",
       "      <td>47828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'s</td>\n",
       "      <td>38615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>was</td>\n",
       "      <td>37042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>movie</td>\n",
       "      <td>35180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>as</td>\n",
       "      <td>29972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>for</td>\n",
       "      <td>29478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>but</td>\n",
       "      <td>29059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>with</td>\n",
       "      <td>28481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token  Frequência\n",
       "10     the      221278\n",
       "24       .      188548\n",
       "49       ,      176455\n",
       "5      and      109996\n",
       "42       a      109552\n",
       "17      of       95082\n",
       "20      to       88314\n",
       "1       is       75184\n",
       "14      it       69164\n",
       "140      i       67269\n",
       "36      in       60621\n",
       "0     this       57822\n",
       "83    that       47828\n",
       "13      's       38615\n",
       "252    was       37042\n",
       "25   movie       35180\n",
       "67      as       29972\n",
       "96     for       29478\n",
       "87     but       29059\n",
       "159   with       28481"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ainda existem muitas stopwords e pontuações\n",
    "freq(train_tokens).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de6111",
   "metadata": {},
   "source": [
    "Tratamento da negação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04116bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_words = [\"not\", \"no\", \"never\", \"none\", \"nor\", \"without\", \"n't\"]\n",
    "sentence_endings = {\".\", \"!\", \"?\"}\n",
    "\n",
    "# Função para o tratamento da negação\n",
    "def negation(tokens):\n",
    "    negated = False\n",
    "    result = []\n",
    "    # A função começa por assumir que não há negação (negated = False)\n",
    "    # Percorre cada token até encontrar uma negation_words\n",
    "    # Se encontrar, ativa a negação até encontrar um sentence_endings\n",
    "    for token in tokens:\n",
    "        if token in negation_words:\n",
    "            negated = True \n",
    "            result.append(token)  \n",
    "        elif token in sentence_endings:  \n",
    "            negated = False\n",
    "            result.append(token)\n",
    "        elif negated:\n",
    "            result.append(f\"NOT_{token}\")\n",
    "        else:\n",
    "            result.append(token)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "train_tokens_neg = train_tokens.apply(negation)\n",
    "# mesmo para o conjunto de teste\n",
    "test_tokens_neg = test_tokens.apply(negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acd67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['done',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'no',\n",
       " 'NOT_big',\n",
       " 'NOT_surprise',\n",
       " 'NOT_when',\n",
       " 'NOT_you',\n",
       " 'NOT_have',\n",
       " 'NOT_people',\n",
       " 'NOT_such',\n",
       " 'NOT_as',\n",
       " 'NOT_vincente',\n",
       " 'NOT_minnelli',\n",
       " 'NOT_and',\n",
       " 'NOT_gene',\n",
       " 'NOT_kelly',\n",
       " 'NOT_at',\n",
       " 'NOT_work',\n",
       " '.',\n",
       " 'but',\n",
       " 'really',\n",
       " ',',\n",
       " 'could']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exemplo de tokens com negação\n",
    "train_tokens_neg[0][200:225]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7ab9a",
   "metadata": {},
   "source": [
    "Eliminar stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [typical, cheerful, colorful, mgm, musical, ea...\n",
       "1        [another, reviewer, states, hanna, 's, war, ou...\n",
       "2        [one, best, ``, amitabh, comeback, '', movies,...\n",
       "3        [peter, sollett, created, endearing, portrait,...\n",
       "4        [film, NOT_visually, NOT_stunning, NOT_convent...\n",
       "                               ...                        \n",
       "21749    [third, entry, phantasm, series, ,, mike, regg...\n",
       "21750    [movie, still, chills, bone, thinking, ., movi...\n",
       "21751    [film, joke, ?, comedy, ?, surely, n't, NOT_se...\n",
       "21752    [david, prior, 's, movies, terrible, counts, :...\n",
       "21753    [movie, sam, wife, ,, glorious, peter, falk, e...\n",
       "Name: text, Length: 21754, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lista de stopwords em inglês\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# Remove as stopwords e também as stopwords que foram negadas (NOT_)\n",
    "train_stopw = train_tokens_neg.apply(lambda x: [\n",
    "    word for word in x if word not in stopwords and not (word.startswith(\"NOT_\") and word[4:] in stopwords)\n",
    "])\n",
    "# mesmo para o conjunto de teste\n",
    "test_stopw = test_tokens_neg.apply(lambda x: [\n",
    "    word for word in x if word not in stopwords and not (word.startswith(\"NOT_\") and word[4:] in stopwords)\n",
    "])\n",
    "\n",
    "# MESMO MAS SEM NEGAÇÃO\n",
    "train_stopw_sn = train_tokens.apply(lambda x: [\n",
    "    word for word in x if word not in stopwords and not (word.startswith(\"NOT_\") and word[4:] in stopwords)])\n",
    "test_stopw_sn = test_tokens.apply(lambda x: [\n",
    "    word for word in x if word not in stopwords and not (word.startswith(\"NOT_\") and word[4:] in stopwords)])\n",
    "\n",
    "train_stopw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numbers',\n",
       " 'also',\n",
       " 'nicely',\n",
       " 'done',\n",
       " ',',\n",
       " 'NOT_big',\n",
       " 'NOT_surprise',\n",
       " 'NOT_people',\n",
       " 'NOT_vincente',\n",
       " 'NOT_minnelli',\n",
       " 'NOT_gene',\n",
       " 'NOT_kelly',\n",
       " 'NOT_work',\n",
       " '.',\n",
       " 'really']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mesmo excerto anterior, mas sem stopwords\n",
    "train_stopw[0][115:130]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38067703",
   "metadata": {},
   "source": [
    "Tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c84053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequência</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.</td>\n",
       "      <td>188548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>,</td>\n",
       "      <td>147873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'s</td>\n",
       "      <td>33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>movie</td>\n",
       "      <td>29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NOT_,</td>\n",
       "      <td>28582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>n't</td>\n",
       "      <td>23453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>film</td>\n",
       "      <td>23216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>!</td>\n",
       "      <td>19186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>(</td>\n",
       "      <td>19113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>)</td>\n",
       "      <td>18602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>``</td>\n",
       "      <td>18384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>''</td>\n",
       "      <td>18211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>one</td>\n",
       "      <td>14811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>like</td>\n",
       "      <td>11167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>?</td>\n",
       "      <td>10891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>good</td>\n",
       "      <td>8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>would</td>\n",
       "      <td>7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>story</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>time</td>\n",
       "      <td>7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>really</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token  Frequência\n",
       "12        .      188548\n",
       "30        ,      147873\n",
       "7        's       33168\n",
       "13    movie       29100\n",
       "114   NOT_,       28582\n",
       "92      n't       23453\n",
       "130    film       23216\n",
       "680       !       19186\n",
       "494       (       19113\n",
       "497       )       18602\n",
       "43       ``       18384\n",
       "46       ''       18211\n",
       "31      one       14811\n",
       "174    like       11167\n",
       "101       ?       10891\n",
       "282    good        8919\n",
       "134   would        7649\n",
       "220   story        7220\n",
       "61     time        7104\n",
       "90   really        6532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ainda temos pontuação (e pontuação negada) e pedaços de palavras soltas\n",
    "freq(train_stopw).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334678e9",
   "metadata": {},
   "source": [
    "Eliminar pontuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "C:\\Users\\vasco\\AppData\\Local\\Temp\\ipykernel_20108\\1474935808.py:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  punctuation = '''!()-[]{};´´``:''\"\\,<>/?@#$%^&...*_~'''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [typical, cheerful, colorful, mgm, musical, ea...\n",
       "1        [another, reviewer, states, hanna, 's, war, ou...\n",
       "2        [one, best, amitabh, comeback, movies, liked, ...\n",
       "3        [peter, sollett, created, endearing, portrait,...\n",
       "4        [film, NOT_visually, NOT_stunning, NOT_convent...\n",
       "                               ...                        \n",
       "21749    [third, entry, phantasm, series, mike, reggie,...\n",
       "21750    [movie, still, chills, bone, thinking, movie, ...\n",
       "21751    [film, joke, comedy, surely, n't, NOT_serious,...\n",
       "21752    [david, prior, 's, movies, terrible, counts, b...\n",
       "21753    [movie, sam, wife, glorious, peter, falk, equa...\n",
       "Name: text, Length: 21754, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "punctuation = '''!()-[]{};´´``:''\"\\,<>/?@#$%^&...*_~'''\n",
    "# Remove a pontuação e também as pontuações que foram negadas (NOT_)\n",
    "train_no_punct = train_stopw.apply(lambda x: [\n",
    "    word for word in x if word not in punctuation and not (word.startswith(\"NOT_\") and word[4:] in punctuation)\n",
    "])\n",
    "# mesmo para o conjunto de teste\n",
    "test_no_punct = test_stopw.apply(lambda x: [\n",
    "    word for word in x if word not in punctuation and not (word.startswith(\"NOT_\") and word[4:] in punctuation)\n",
    "])\n",
    "\n",
    "# MESMO MAS SEM NEGAÇÃO\n",
    "train_no_punct_sn = train_stopw_sn.apply(lambda x: [\n",
    "    word for word in x if word not in punctuation and not (word.startswith(\"NOT_\") and word[4:] in punctuation)])\n",
    "test_no_punct_sn = test_stopw_sn.apply(lambda x: [\n",
    "    word for word in x if word not in punctuation and not (word.startswith(\"NOT_\") and word[4:] in punctuation)])\n",
    "\n",
    "train_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0dbfe",
   "metadata": {},
   "source": [
    "Tokens mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eb26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequência</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'s</td>\n",
       "      <td>33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>movie</td>\n",
       "      <td>29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>n't</td>\n",
       "      <td>23453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>film</td>\n",
       "      <td>23216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>one</td>\n",
       "      <td>14811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>like</td>\n",
       "      <td>11167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>good</td>\n",
       "      <td>8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>would</td>\n",
       "      <td>7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>story</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>time</td>\n",
       "      <td>7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>really</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>see</td>\n",
       "      <td>6521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>well</td>\n",
       "      <td>6274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NOT_movie</td>\n",
       "      <td>6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>great</td>\n",
       "      <td>5911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>could</td>\n",
       "      <td>5626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>even</td>\n",
       "      <td>5559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>NOT_'s</td>\n",
       "      <td>5447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>people</td>\n",
       "      <td>5444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>also</td>\n",
       "      <td>5387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Frequência\n",
       "7           's       33168\n",
       "12       movie       29100\n",
       "88         n't       23453\n",
       "124       film       23216\n",
       "29         one       14811\n",
       "168       like       11167\n",
       "275       good        8919\n",
       "128      would        7649\n",
       "213      story        7220\n",
       "57        time        7104\n",
       "86      really        6532\n",
       "231        see        6521\n",
       "182       well        6274\n",
       "92   NOT_movie        6080\n",
       "230      great        5911\n",
       "87       could        5626\n",
       "429       even        5559\n",
       "440     NOT_'s        5447\n",
       "251     people        5444\n",
       "58        also        5387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ainda temos pedaços de palavras soltas (ex.'s e n't, e as mesmas negadas)\n",
    "freq(train_no_punct).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc0dd9",
   "metadata": {},
   "source": [
    "Eliminar afixos soltos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c39f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [typical, cheerful, colorful, mgm, musical, ea...\n",
       "1        [another, reviewer, states, hanna, war, outsta...\n",
       "2        [one, best, amitabh, comeback, movies, liked, ...\n",
       "3        [peter, sollett, created, endearing, portrait,...\n",
       "4        [film, NOT_visually, NOT_stunning, NOT_convent...\n",
       "                               ...                        \n",
       "21749    [third, entry, phantasm, series, mike, reggie,...\n",
       "21750    [movie, still, chills, bone, thinking, movie, ...\n",
       "21751    [film, joke, comedy, surely, NOT_serious, NOT_...\n",
       "21752    [david, prior, movies, terrible, counts, bad, ...\n",
       "21753    [movie, sam, wife, glorious, peter, falk, equa...\n",
       "Name: text, Length: 21754, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loose_affixes = [\"n't\", \"'s\",\"'ve\", \"'re\", \"'ll\", \"'d\", \"'m\", \"'t\"]\n",
    "# Remove os afixos soltos e também os que foram negados (NOT_)\n",
    "train_clean = train_no_punct.apply(lambda x: [\n",
    "    word for word in x if word not in loose_affixes and not (word.startswith(\"NOT_\") and word[4:] in loose_affixes)\n",
    "])\n",
    "# mesmo para o conjunto de teste\n",
    "test_clean = test_no_punct.apply(lambda x: [\n",
    "    word for word in x if word not in loose_affixes and not (word.startswith(\"NOT_\") and word[4:] in loose_affixes)\n",
    "])\n",
    "\n",
    "# MESMO MAS SEM NEGAÇÃO\n",
    "train_clean_sn = train_no_punct_sn.apply(lambda x: [\n",
    "    word for word in x if word not in loose_affixes and not (word.startswith(\"NOT_\") and word[4:] in loose_affixes)])\n",
    "test_clean_sn = test_no_punct_sn.apply(lambda x: [\n",
    "    word for word in x if word not in loose_affixes and not (word.startswith(\"NOT_\") and word[4:] in loose_affixes)])\n",
    "\n",
    "train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b22c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequência</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>movie</td>\n",
       "      <td>29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>film</td>\n",
       "      <td>23216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>one</td>\n",
       "      <td>14811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>like</td>\n",
       "      <td>11167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>good</td>\n",
       "      <td>8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>would</td>\n",
       "      <td>7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>story</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>time</td>\n",
       "      <td>7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>really</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>see</td>\n",
       "      <td>6521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>well</td>\n",
       "      <td>6274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>NOT_movie</td>\n",
       "      <td>6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>great</td>\n",
       "      <td>5911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>could</td>\n",
       "      <td>5626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>even</td>\n",
       "      <td>5559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>people</td>\n",
       "      <td>5444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>also</td>\n",
       "      <td>5387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>first</td>\n",
       "      <td>5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>bad</td>\n",
       "      <td>5223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>made</td>\n",
       "      <td>4972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Frequência\n",
       "11       movie       29100\n",
       "122       film       23216\n",
       "28         one       14811\n",
       "166       like       11167\n",
       "273       good        8919\n",
       "126      would        7649\n",
       "211      story        7220\n",
       "56        time        7104\n",
       "85      really        6532\n",
       "229        see        6521\n",
       "180       well        6274\n",
       "90   NOT_movie        6080\n",
       "228      great        5911\n",
       "86       could        5626\n",
       "427       even        5559\n",
       "249     people        5444\n",
       "57        also        5387\n",
       "566      first        5312\n",
       "499        bad        5223\n",
       "183       made        4972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq(train_clean).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de828e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequência</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>movie</td>\n",
       "      <td>29102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>film</td>\n",
       "      <td>23292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>one</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>like</td>\n",
       "      <td>11201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>good</td>\n",
       "      <td>8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>would</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>story</td>\n",
       "      <td>6984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>time</td>\n",
       "      <td>6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>see</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>well</td>\n",
       "      <td>6485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>really</td>\n",
       "      <td>6422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NOT_movie</td>\n",
       "      <td>6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>great</td>\n",
       "      <td>6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>could</td>\n",
       "      <td>5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>even</td>\n",
       "      <td>5462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>also</td>\n",
       "      <td>5360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>people</td>\n",
       "      <td>5262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>bad</td>\n",
       "      <td>5218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>first</td>\n",
       "      <td>5119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>movies</td>\n",
       "      <td>5084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Frequência\n",
       "66       movie       29102\n",
       "93        film       23292\n",
       "156        one       15186\n",
       "331       like       11201\n",
       "348       good        8939\n",
       "273      would        7639\n",
       "124      story        6984\n",
       "64        time        6971\n",
       "218        see        6651\n",
       "71        well        6485\n",
       "122     really        6422\n",
       "37   NOT_movie        6310\n",
       "114      great        6100\n",
       "576      could        5587\n",
       "13        even        5462\n",
       "394       also        5360\n",
       "271     people        5262\n",
       "299        bad        5218\n",
       "177      first        5119\n",
       "592     movies        5084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq(test_clean).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv\n",
    "#train_clean.to_csv(\"train_clean.csv\", index=False, encoding=\"utf-8\")\n",
    "# csv\n",
    "#test_clean.to_csv(\"test_clean.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# MESMO MAS SEM NEGAÇÃO\n",
    "#train_clean_sn.to_csv(\"train_clean_sn.csv\", index=False, encoding=\"utf-8\")\n",
    "# csv\n",
    "#test_clean_sn.to_csv(\"test_clean_sn.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
